
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 10: Predictive Modeling - Part 1"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](fa2021_assignment10.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Install the package `mlbench` and use the follows to import the data

```{r}
library(tidyverse)
library(mlbench)
data(PimaIndiansDiabetes)
df <- PimaIndiansDiabetes
```

- Set seed to be 2020. 
- The target variable is `diabetes`
- Partition the data into 80% training and 20% testing.  
```{r}
library(caret)
set.seed(2020)
names(df)[9]<-'diabetes'
splitIndex <- createDataPartition(df$diabetes, p = .80, list = FALSE)
df_train <- df[splitIndex,]
df_test <- df[-splitIndex,]
```

-------

2. Practice Decision Tree.  Do the follows:

  - Use `rpart` package, create a decision tree with maximum depth of 3. 
  
  - Calculate the accuracy of the model on the testing data. 
  
  - Plot the tree
  
  - Plot the variable importance by the tree
```{r}
library(rpart)

tree_model <- rpart(diabetes ~ ., data = df_train, control = rpart.control(maxdepth = 3))

pred <- predict(tree_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$diabetes, positive = "pos")
cm$overall[1]

library(rattle)
fancyRpartPlot(tree_model)

tree_model$variable.importance
barplot(tree_model$variable.importance)
```

-------

3. Practice Random Forest.  Do the follows: 

  - Use `randomForest` package, create a random forest of 1000 trees. 
  
  - Calculate the accuracy of the model on the testing data. 
  
  - Plot the variable importance by the forest
```{r}
library(randomForest)
forest_model = randomForest(diabetes ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")

cm <- confusionMatrix(data = pred, reference = df_test$diabetes, positive = "pos")
cm$overall[1]

forest_model$importance
```

-------

4. Compare the testing accuracy of a forest of 1000 trees and a forest of 2000 trees. 
```{r}
#model_1
model_1 = randomForest(diabetes~., data=df_train, ntree = 1000)
pred <- predict(model_1, df_test, type="class")
cm <- confusionMatrix(data=pred, reference=df_test$diabetes, positive="pos")
cm$overall[1]

#model2
model_2 = randomForest(diabetes~., data=df_train,ntree = 2000)
pred <- predict(model_2, df_test, type="class")

cm <- confusionMatrix(data=pred, reference=df_test$diabetes, positive="pos")
cm$overall[1]
```

-------

5. Using Caret, create a tree with maximum depth of 3 and forest of 1000 trees. Compare the accuracy of these two models.
```{r}
#model1
model1 <- train(diabetes~., data=df_train, method = "rpart2", maxdepth=3)
pred <- predict(model1, df_test)

cm <- confusionMatrix(data = pred, reference = df_test$diabetes, positive="pos")
cm$overall[1]


#model2
model2 <- train(diabetes~., data=df_train, method ='rf', ntree = 1000)
pred <- predict(model2, df_test)

cm <- confusionMatrix(data=pred, reference = df_test$diabetes, positive = "pos")
cm$overall[1]
```

-------

6. Plot variable importance by the two models in 5. 
```{r}
#model1
varImp(model1)
plot(varImp(model1))

#model2
varImp(model2)
plot(varImp(model2))
```

-------

7. (Optional - For extra credits only) Use your own selected data.  Do the follows. 
```{r}
library(tidyverse)
df = read_csv("wine.csv")
```

- Handle missing values if any
```{r}
df = drop_na(df)
```

- Put the variables in the right format (categorical vs. continuous)
```{r}
df$quality <- factor(df$quality)
```

- Select a binary target variable (Use can create a binary target variable from a continuous variable). 
```{r}
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$quality, p = .70, 
                                  list = FALSE)
df_train <- df[splitIndex,]
df_test <- df[-splitIndex,]
```

- Using caret with method `ranger` to train then test the accuracy of a random forest of 1000 trees. 
```{r}
model1 <- train(quality~., data=df_train, 
                method = "ranger",
               num.trees = 1000)
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$quality, positive = "good")
cm$overall[1]
```

